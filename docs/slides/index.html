<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>reveal.js</title>

		<link rel="stylesheet" href="reveal.js/dist/reset.css">
		<link rel="stylesheet" href="reveal.js/dist/reveal.css">
		<link rel="stylesheet" href="reveal.js/dist/theme/black.css" id="theme">

		<!-- Theme used for syntax highlighted code -->
		<link rel="stylesheet" href="reveal.js/plugin/highlight/monokai.css" id="highlight-theme">
	</head>
	<body>
		<div class="reveal">
			<div class="slides" style="text-align: left;">
				<section data-markdown>
					## Azure ML 2.0 Developer Experience	
					
					AzureML is creating a new developer experience
					starting with: 

					- CLI + ARM interface
					- Core SDK for Python
					- REST API and autogenerated SDK for Go, Java, JS and .Net
					
					...for control plane operations + MLFlow for data plane operations

					Notes:
					Why do this at all?
					- Our v1 API is showing too much of the AzureML org-chart.
					- Simple things can be surprisingly hard in v1.

					Why start with CLI?
					- In v1 CLI is the most limited and inconsistent surface
				</section>
				<section>
					<section data-markdown>
						#### Hierarchy of entity types in DevPlatV2

						![](media/nouns.png)

						Notes:
						- the new system is built on a hierarchy of entity types
						- the hierarchy determines which properties the different types share 
						- note that there are abstract and concrete types -- only concrete types can have instances
					</section>
					<section data-markdown data-auto-animate>
						## The CLI

						Consistency between the different nouns where possible

						Create an entity:
						```bash
						az ml job create --file my_job.yaml 
						az ml environment create --file my_env.yaml
						az ml model created --file my_model.yaml
						```
					</section>
					<section data-markdown data-auto-animate>
						## The CLI

						Consistency between the different nouns where possible

						Show an entity:
						```bash
						az ml job show --name 'the job' 
						az ml environment show --name 'the environment' 
						az ml model show --name 'the model'
						```
					</section>				
					<section data-markdown data-auto-animate>
						## The CLI

						Consistency between the different nouns where possible
						
						Update an entity:
						```bash
						az ml job update --name 'the job' --set tags.beta=True 
						az ml environment update --name 'the environment' --set tags.beta=True 
						az ml model update --name 'the model' --set tags.beta=True
						```
					</section>
					<section data-markdown data-auto-animate>
						## The CLI

						Consistency between the different nouns where possible

						Delete an entity:
						```bash
						az ml job delete --name 'the job' 
						az ml environment delete --name 'the environment' 
						az ml model update --name 'the model'
						```
					</section>
					<section data-markdown data-auto-animate>
						## The CLI

						Consistency between the different nouns where possible

						List entities:
						```bash
						az ml job list 
						az ml environment list
						az ml model list
						```
					</section>
				</section>
				<section>
					<section data-markdown data-auto-animate style="text-align: left;">
						## The YAML

						Every entity has a YAML representation that is used for `create` and that is returned by `show`

						Simple `command_job` example:
						```yaml 
						command: python hello_pytorch.py
						code: 
							directory: src
						environment: 
							docker: 
								image: docker.io/pytorch/pytorch
						compute:
							target: azureml:v100Cluster
						```
					</section>
					<section data-markdown data-auto-animate style="text-align: left;">
						## The YAML

						Every entity has a YAML representation that is used for `create` and that is returned by `show`

						Simple `command_job` example:
						```yaml 
						command: python hello_pytorch.py
						code: 
							directory: src
						environment: 
							docker: 
								image: docker.io/pytorch/pytorch
						compute:
							target: azureml:v100Cluster
						```

						Submit the job via `az ml job create`:
						```bash
						az ml job create --file above.yaml
						```
					</section>
					<section data-markdown data-auto-animate style="text-align: left;">
						There is terrific help from VSCode to edit the yaml files:
						![](media/yamlschema.gif)
					</section>
				</section>
				<section>
					<section data-markdown data-auto-animate style="text-align: left;">
						## `environment`

						Create environment based on a dockerfile
						```yaml 
						# yaml-language-server: $schema=https://azuremlsdk2.blob.core.windows.net/latest/environment.schema.json
						name: fastai-vision
						version: 1
						docker:
							build:
								dockerfile: file:fastai.dockerfile
						```

					</section>
					<section data-markdown data-auto-animate style="text-align: left;">
						## `environment`

						Create environment based on an existing docker image
						```yaml 
						# yaml-language-server: $schema=https://azuremlsdk2.blob.core.windows.net/latest/environment.schema.json
						name: fastai-vision
						version: 1
						docker:
							image: docker.io/fastai/fastai
						```
					</section>
					<section data-markdown data-auto-animate style="text-align: left;">
						## `environment`

						Create environment based on conda definition
						```yaml 
						# yaml-language-server: $schema=https://azuremlsdk2.blob.core.windows.net/latest/environment.schema.json
						name: fastai-vision
						version: 1
						conda_file: file:fastai-conda-env.yml
						```
					</section>
					<section data-markdown data-auto-animate style="text-align: left;">
						## `environment`

						Create environment based on conda definition
						```yaml 
						# yaml-language-server: $schema=https://azuremlsdk2.blob.core.windows.net/latest/environment.schema.json
						name: fastai-vision
						version: 1
						conda_file: file:fastai-conda-env.yml
						```
						creating the environment is always:
						```bash
						az ml environment create --file fastai-vision-env.yml  
						```
					</section>
				</section>
				<section>
					<section data-markdown data-auto-animate style="text-align: left;">
						## `data`

						Create a dataset based on data already in the cloud
						```yaml 
						# yaml-language-server: $schema=https://azuremlsdk2.blob.core.windows.net/latest/asset.schema.json
						name: irisdata
						version: 1
						description: "iris data"
						datastore: "azureml:workspaceblobstore"
						directory: data
						```
						CLI command:
						```bash
						az ml data create --file iris-data.yaml
						```
						Notes: az ml data create --file iris-data.yaml --version 4
					</section>
					<section data-markdown data-auto-animate style="text-align: left;">
						## `data`

						Create a dataset by uploading data
						```bash
						cd ./iris/
						az ml data upload --name irisdata --version 1 --path ./data
						```
					</section>
				</section>

				<section>
					<section data-markdown data-auto-animate style="text-align: left;">
						## `command_job`

						```yaml [1|2|3-4|5-7|8-9]
						# yaml-language-server: $schema=https://azuremlsdk2.blob.core.windows.net/latest/commandJob.schema.json
						command: python hello.py
						code:
							directory: src
						environment: 
							docker: 
								image: docker.io/python
						compute:
							target: azureml:goazurego
						```
					</section>

					<section data-markdown data-auto-animate style="text-align: left;">
						## `command_job`

						```yaml
						# yaml-language-server: $schema=https://azuremlsdk2.blob.core.windows.net/latest/commandJob.schema.json
						command: python hello.py
						code:
							directory: src
						environment: 
							docker: 
								image: docker.io/python
						compute:
							target: azureml:goazurego
						```

						Submit the job via `az ml job create`:
						```bash
						az ml job create --file hello_python_job.yml --stream 
						```
						Notes:
						- no name on a job means that the system will choose one
					</section>
					<section data-markdown data-auto-animate style="text-align: left;">
						## `command_job`

						```yaml [8|6|11-14]
						# yaml-language-server: $schema=https://azuremlsdk2.blob.core.windows.net/latest/commandJob.schema.json
						code: 
							directory: train
						command: >-
							python train.py 
							--data {inputs.training_data} 
					
						environment: azureml:xgboost-env:1
						compute:
							target: azureml:goazurego
						inputs:
							training_data:
								data: azureml:irisdata:1
								mode: mount
						```

						Submit the job via `az ml job create`:
						```bash
						az ml job create --file iris_job.yml --stream 
						```
					</section>
					<section data-markdown data-auto-animate>
						## `sweep_job` (WIP)

						```yaml [|6-17|18-24|25-28|29-37]
						# yaml-language-server: $schema=https://azuremlsdk2.blob.core.windows.net/latest/sweepJob.schema.json
						experiment_name: sweep-trial-v3
						algorithm: random
						type: sweep_job
						name: test_v3111
						search_space:
							lr:
								type: uniform
								min_value: 0.001
								max_value: 0.1
							conv_size:
								type: choice
								values: [2, 5, 7]
							dropout_rate:
								type: uniform
								min_value: 0.1
								max_value: 0.5     
						trial: 
							command: python train.py --lr {search_space.lr} --conv_size {search_space.conv_size} --dropout_rate {search_space.dropout_rate}
							code: 
								directory: src
							environment: azureml:AzureML-Minimal:1
							compute:
								target: azureml:testCompute
						limits:
							max_total_trials: 100
							max_concurrent_trials: 10
							timeout_minutes: 10000
						early_termination:
							policy_type: truncation_selection
							evaluation_interval: 100
							delay_evaluation: 200
							truncation_percentage: 40
							exclude_finished_jobs: True
						objective:
							primary_metric: accuracy
							goal: maximize
						```
					</section>
					<section data-markdown data-auto-animate>
						## `sweep_job` (WIP)

						```yaml
						# yaml-language-server: $schema=https://azuremlsdk2.blob.core.windows.net/latest/sweepJob.schema.json
						experiment_name: sweep-trial-v3
						algorithm: random
						type: sweep_job
						name: test_v3111
						search_space:
							lr:
								type: uniform
								min_value: 0.001
								max_value: 0.1
							conv_size:
								type: choice
								values: [2, 5, 7]
							dropout_rate:
								type: uniform
								min_value: 0.1
								max_value: 0.5     
						trial: 
							command: python train.py --lr {search_space.lr} --conv_size {search_space.conv_size} --dropout_rate {search_space.dropout_rate}
							code: 
								directory: src
							environment: azureml:AzureML-Minimal:1
							compute:
								target: azureml:testCompute
						limits:
							max_total_trials: 100
							max_concurrent_trials: 10
							timeout_minutes: 10000
						early_termination:
							policy_type: truncation_selection
							evaluation_interval: 100
							delay_evaluation: 200
							truncation_percentage: 40
							exclude_finished_jobs: True
						objective:
							primary_metric: accuracy
							goal: maximize
						```
						Submit the job via `az ml job create`:
						```bash
						az ml job create --file iris_sweep_job.yml
						```
					</section>
				</section>	
				<section>
					<section data-markdown data-auto-animate>
						## `model`
						
						A minimal Model:
						```yaml
						# yaml-language-server: $schema=https://azuremlsdk2.blob.core.windows.net/latest/model.schema.json
						name: my-model
						version: 1
						asset_path: ./model
						```
					</section>
					<section data-markdown data-auto-animate>
						## `model`
						
						A more full-fledged model with MLFlow properties:
						```yaml [3|6|7-11|12-15]
						# yaml-language-server: $schema=https://azuremlsdk2.blob.core.windows.net/latest/model.schema.json
						name: my-model
						asset_path: .
						version: 1
						description: this is a SkLearn model
						flavors:
							python_function:
								data: model.pkl
								env: conda.yaml
								loader_module: mlflow.sklearn
								python_version: 3.8.2
							sklearn:
								pickled_model: model.pkl
								serialization_format: cloudpickle
								sklearn_version: 0.23.1
						```
					</section>
					<section data-markdown data-auto-animate>
						## `model`
						
						A more full-fledged model with MLFlow properties:
						```yaml
						# yaml-language-server: $schema=https://azuremlsdk2.blob.core.windows.net/latest/model.schema.json
						name: my-model
						asset_path: .
						version: 1
						description: this is a SkLearn model
						flavors:
							python_function:
								data: model.pkl
								env: conda.yaml
								loader_module: mlflow.sklearn
								python_version: 3.8.2
							sklearn:
								pickled_model: model.pkl
								serialization_format: cloudpickle
								sklearn_version: 0.23.1
						```

						...and creating the model works as expected:
						```bash
						az ml model create --file mlflow-model.yml
						```
					</section>
				</section>
				<section data-markdown>
					## `endpoints` (WIP)

					```yaml
					# yaml-language-server: $schema=https://azuremlsdk2.blob.core.windows.net/latest/onlineEndpoint.schema.json
					location: centraluseuap
					name: myendpoint2
					type: online
					infrastructure: azureml:myakscluster
					auth_mode: key
					traffic:
						blue: 0
						deployments:
							blue: #blue deployment
								model: azureml:my-model-123:3
								sku: Standard_FS4_v2
								scale_settings:
									scale_type: manual
									instance_count: 1
									minimum: 1
									maximum: 1
								request_settings:
									request_timeout_ms: 3000
									max_concurrent_requests_per_instance: 1
									max_queue_wait_ms: 3000
								resource_requirements:
									cpu: 1.0
									memory: 1 Gib
					```
				</section>
				<section data-markdown>
					Many more entities are in the works:
					- `pipline_job`
					- `automl_job`
					- `batch_endpoint` (batch inferencing)
					- `amlk8s_compute` (k8s cluster attach)
					- `table` (tabular dataset)
					- `component` (to composed pipelines)
				</section>
				<section data-markdown>
					Try out the new CLI by visiting this URL:

					[https://aka.ms/azuremlv2](https://aka.ms/azuremlv2) 

					To provide feedback, please open issues on this Github repository:

					[https://github.com/Azure/azureml-v2-preview](https://github.com/Azure/azureml-v2-preview)
				</section>
			</div>
		</div>

		<script src="reveal.js/dist/reveal.js"></script>
		<script src="reveal.js/plugin/notes/notes.js"></script>
		<script src="reveal.js/plugin/markdown/markdown.js"></script>
		<script src="reveal.js/plugin/highlight/highlight.js"></script>
		<script>
			// More info about initialization & config:
			// - https://revealjs.com/initialization/
			// - https://revealjs.com/config/
			Reveal.initialize({
				hash: true,

				// Learn about plugins: https://revealjs.com/plugins/
				plugins: [ RevealMarkdown, RevealHighlight, RevealNotes ]
			});
		</script>
	</body>
</html>
